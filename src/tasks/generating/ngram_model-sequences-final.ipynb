{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://www.nltk.org/api/nltk.lm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set order of n-grams (1=unigram, 2=bigram, ...)\n",
    "n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.80121909922113\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import flatten\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from Bio import SeqIO, SeqRecord \n",
    "from Bio.Seq import Seq\n",
    "\n",
    "seqs = []\n",
    "lens = []\n",
    "# for record in SeqIO.parse(\"data/reference_data/Russ_994_random.fasta\", \"fasta\"):\n",
    "for record in SeqIO.parse(\"data/reference_data/tautomerase_2953.fasta\", \"fasta\"):\n",
    "#     print(record)\n",
    "    seqs.append(list(record.seq))\n",
    "    lens.append(len(record.seq))\n",
    "\n",
    "print(sum(lens)/len(lens)) # avg length\n",
    "print(lens[len(lens)//2]) # median length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default preprocessing for a sequence of sentences.\n",
    "\n",
    "# Creates two iterators:\n",
    "# - sentences padded and turned into sequences of `nltk.util.everygrams`\n",
    "# - sentences padded as above and chained together for a flat stream of words\n",
    "\n",
    "# :param order: Largest ngram length produced by `everygrams`.\n",
    "# :param text: Text to iterate over. Expected to be an iterable of sentences:\n",
    "# Iterable[Iterable[str]]\n",
    "# :return: iterator over text as ngrams, iterator over text as vocabulary data\n",
    "train, vocab = padded_everygram_pipeline(n, seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 23 items>\n",
      "<NgramCounter with 4 ngram orders and 759526 ngrams>\n"
     ]
    }
   ],
   "source": [
    "lm = MLE(n)\n",
    "\n",
    "lm.fit(train, vocab)\n",
    "\n",
    "print(lm.vocab)\n",
    "print(lm.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE that <s> and <\\s> delineate start and end of sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'R', 'E', 'G', 'S']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# provide random_seed for consistent output\n",
    "lm.generate(5, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'F', 'I', 'N', 'D', 'M', 'P', 'E', 'G', 'T', 'N', 'T', 'A', 'S', 'E', 'I', 'T', 'R', 'V', 'M', 'V', 'K', 'V', 'T', 'N', 'A', 'Q', 'K', 'Q', 'K', 'L', 'E', 'L', 'R', 'L', 'T', 'E', 'V', 'V', 'S', 'R', 'S', 'L', 'A', 'E', 'H', 'V', 'H', 'V', 'L']\n"
     ]
    }
   ],
   "source": [
    "# condition on preceding text. verify this works correctly\n",
    "print(lm.generate(50, text_seed=['<s>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "sequences = []\n",
    "while len(results) < 226:\n",
    "    r = lm.generate(92, text_seed=['<s>'])\n",
    "    if not '<s>' in r and not '</s>' in r:\n",
    "        sequences.append(SeqRecord.SeqRecord(id=str(len(results)),seq=Seq(''.join(r))))\n",
    "        results.append(r)\n",
    "\n",
    "with open(\"Russ_994_random_4gram_generation_seed_<s>_len92.fasta\", \"w\") as output_handle:\n",
    "    SeqIO.write(sequences, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "sequences = []\n",
    "while len(results) < 226:\n",
    "    r = lm.generate(92, text_seed=['<s>', 'M', 'T', 'S', 'E', 'N', 'P', 'L', 'L', 'A', 'L', 'R', 'E', 'K', 'I', 'S', 'A', 'L', 'D', 'E', 'K'])\n",
    "    if not '<s>' in r and not '</s>' in r:\n",
    "        sequences.append(SeqRecord.SeqRecord(id=str(len(results)),seq=Seq(''.join(r))))\n",
    "        results.append(r)\n",
    "\n",
    "with open(\"Russ_994_random_4gram_generation_seed_<s>MTSENPLLALREKISALDEK_len92.fasta\", \"w\") as output_handle:\n",
    "    SeqIO.write(sequences, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "sequences = []\n",
    "while len(results) < 738:\n",
    "    r = lm.generate(60, text_seed=['<s>'])\n",
    "    if not '<s>' in r and not '</s>' in r:\n",
    "        sequences.append(SeqRecord.SeqRecord(id=str(len(results)),seq=Seq(''.join(r))))\n",
    "        results.append(r)\n",
    "\n",
    "with open(\"tautomerase_2953_4gram_generation_seed_<s>_len60.fasta\", \"w\") as output_handle:\n",
    "    SeqIO.write(sequences, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "sequences = []\n",
    "while len(results) < 738:\n",
    "    r = lm.generate(60, text_seed=text_seed=['<s>', 'M', 'T', 'S', 'E', 'N', 'P', 'L', 'L', 'A', 'L', 'R', 'E', 'K', 'I', 'S', 'A', 'L', 'D', 'E', 'K'])\n",
    "    if not '<s>' in r and not '</s>' in r:\n",
    "        sequences.append(SeqRecord.SeqRecord(id=str(len(results)),seq=Seq(''.join(r))))\n",
    "        results.append(r)\n",
    "\n",
    "with open(\"tautomerase_2953_4gram_generation_seed_<s>MTSENPLLALREKISALDEK_len60.fasta\", \"w\") as output_handle:\n",
    "    SeqIO.write(sequences, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9779"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.counts['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.counts[['A']]['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09160055078355518"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007464975968912977"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prob of C preceded by A\n",
    "lm.score(\"C\", [\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.448499916667411"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log to avoid underflow (too small numbers multiplied)\n",
    "lm.logscore(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [tuple('AC')]\n",
    "\n",
    "# Calculate cross-entropy of model for given evaluation text.\n",
    "lm.entropy(test)\n",
    "\n",
    "# Calculates the perplexity of the given text.\n",
    "# This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
    "lm.perplexity(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens with counts greater than or equal to the cutoff value will be considered part of the vocabulary.\n",
    "words = ['a', 'c', '-', 'd', 'c', 'a', 'b', 'r', 'a', 'c', 'd']\n",
    "from nltk.lm import Vocabulary\n",
    "vocab = Vocabulary(words, unk_cutoff=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
